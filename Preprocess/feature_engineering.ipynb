{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kevin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from transformers import *\n",
    "from corpus_helper import CorpusStreamer\n",
    "\n",
    "init_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction = Pipeline([\n",
    "    (\"TextCleaner\",TextCleaner()),\n",
    "    (\"NamedEntityMasker\", NamedEntityMasker([\"PERSON\"], maskwith=\"person\")),\n",
    "    (\"TextFeatureExtractor\", TextFeatureExtractor()),\n",
    "])\n",
    "\n",
    "\n",
    "feature_encoding = Pipeline([(\"_union\", FeatureUnion([\n",
    "        (\"_W2V\", Pipeline([\n",
    "            (\"_ColumnSelector_Words\", ColumnSelector([0])),\n",
    "            (\"TextVectorizer\", TextVectorizer())\n",
    "        ])),\n",
    "        (\"_OtherFeatures\", Pipeline([\n",
    "            (\"_ColumnSelector_!Words\", ColumnSelector([0], inverse=True)),\n",
    "            (\"_union\", FeatureUnion([\n",
    "                (\"_discrete_features\", Pipeline([\n",
    "                    (\"TypeSelector_Discrete\", TypeSelector([\"object\", \"category\"])),\n",
    "                    (\"LabelBinarizer\", OneHotEncoder())\n",
    "                ])),\n",
    "                (\"_continous_features\", Pipeline([\n",
    "                    (\"TypeSelector_Continuous\", TypeSelector([\"number\"])),\n",
    "                    (\"MinMaxScaler\", MinMaxScaler(feature_range=[-1,1]))\n",
    "                ]))\n",
    "            ]))\n",
    "        ])),\n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teststring = \"This is a test with three sentences. Indices should be reset here. Sarah is not home.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dickensdata = CorpusStreamer(\"../DataAcquisition/data/dickens\")\n",
    "s2 = dickensdata.toString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_pipeline(X, pipeline, chunksize):\n",
    "    Xt = None\n",
    "    start = 0\n",
    "    chunksize = 10**6\n",
    "    while True:\n",
    "        print(\"Iteration {} / {}\".format(start // chunksize, len(X) // chunksize + 1))\n",
    "        part = X[start:start+chunksize]\n",
    "        Xt = pd.concat((Xt, pipeline.fit_transform(part)), ignore_index=True)\n",
    "\n",
    "        if len(part) < chunksize:\n",
    "            break\n",
    "\n",
    "        start += chunksize\n",
    "    \n",
    "    return Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s2[0:10**6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 / 34\n",
      "Iteration 1 / 34\n",
      "Iteration 2 / 34\n",
      "Iteration 3 / 34\n",
      "Iteration 4 / 34\n",
      "Iteration 5 / 34\n",
      "Iteration 6 / 34\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = apply_pipeline(s2, feature_extraction, 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = feature_encoding.fit_transform(X)\n",
    "with open(\"../DataAcquisition/data/wells/wells_enc.pkl\", \"wb\") as f:\n",
    "    pkl.dump(encoded, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
